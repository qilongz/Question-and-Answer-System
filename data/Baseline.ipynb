{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math,numpy,json,re,nltk\n",
    "import time,re,os.path,sys\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from collections import defaultdict\n",
    "from numpy import multiply\n",
    "from math import sqrt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os.path as path\n",
    "from collections import OrderedDict\n",
    "from nltk.stem.wordnet import WordNetLemmatizer as WNL\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from nltk import FreqDist, DictionaryProbDist\n",
    "from operator import add\n",
    "import csv, ast\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "import string\n",
    "path_to_jar = 'data/stanford-parser.jar'\n",
    "path_to_models_jar = 'data/stanford-parser-3.7.0-models.jar'\n",
    "st=PorterStemmer()\n",
    "stop = set(stopwords.words('english'))\n",
    "json_data = []\n",
    "json_dataPOS = []\n",
    "json_dataPOSOrg = []\n",
    "dictDoc = {}\n",
    "dictDocOrg = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def json_load_byteified(file_handle):\n",
    "    return _byteify(json.load(file_handle, object_hook=_byteify),ignore_dicts=True)\n",
    "\n",
    "def _byteify(data, ignore_dicts = False):\n",
    "    # if this is a unicode string, return its string representation\n",
    "    if isinstance(data, unicode):\n",
    "        return data.encode('utf-8')\n",
    "    # if this is a list of values, return list of byteified values\n",
    "    if isinstance(data, list):\n",
    "        return [ _byteify(item, ignore_dicts=True) for item in data ]\n",
    "    # if this is a dictionary, return dictionary of byteified keys and values\n",
    "    # but only if we haven't already byteified it\n",
    "    if isinstance(data, dict) and not ignore_dicts:\n",
    "        return {\n",
    "            _byteify(key, ignore_dicts=True): _byteify(value, ignore_dicts=True)\n",
    "            for key, value in data.iteritems()\n",
    "        }\n",
    "    # if it's anything else, return it in its original form\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def num_there(s):\n",
    "    return any(i.isdigit() for i in s)\n",
    "\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def importNERPOSQA(NER,POS,QA):\n",
    "    global json_data, json_dataPOS, json_dataOrg, json_dataPOSOrg, dictDoc, dictDocOrg\n",
    "    with open(NER) as json_file:\n",
    "        json_data = json_load_byteified(json_file)    \n",
    "    with open(POS) as json_file:\n",
    "        json_dataPOS = json_load_byteified(json_file)\n",
    "    with open(QA) as json_file:\n",
    "        json_dataOrg = json_load_byteified(json_file)\n",
    "    with open(POS) as json_file:\n",
    "        json_dataPOSOrg = json_load_byteified(json_file)\n",
    "    for document in range(len(json_data)):\n",
    "        for thing in range(len(json_data[document])):\n",
    "            for sentence in range(len(json_data[document][thing])):\n",
    "                for word in range(len(json_data[document][thing][sentence])):\n",
    "                    json_data[document][thing][sentence][word][1] = 'U' if word!=0 and json_data[document][thing][sentence][word][0][0].isupper() and json_data[document][thing][sentence][word][1]=='O' else json_data[document][thing][sentence][word][1]\n",
    "                    json_data[document][thing][sentence][word][0] = json_data[document][thing][sentence][word][0].lower()\n",
    "                    if json_data[document][thing][sentence][word][0] in ['one','two','three','four','five','six','seven','eight','nine','ten','zero'] or isfloat(json_data[document][thing][sentence][word][0]):\n",
    "                        json_data[document][thing][sentence][word][1] = 'NUMBER'\n",
    "    for document in range(len(json_dataPOS)):\n",
    "        for thing in range(len(json_dataPOS[document])):\n",
    "            for sentence in range(len(json_dataPOS[document][thing])):\n",
    "                for word in range(len(json_dataPOS[document][thing][sentence])):\n",
    "                    json_dataPOS[document][thing][sentence][word][0] = json_dataPOS[document][thing][sentence][word][0].lower()\n",
    "                    if num_there(json_dataPOS[document][thing][sentence][word][0]):\n",
    "                        json_dataPOS[document][thing][sentence][word][1] = 'CD'\n",
    "    print 'import success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def detectQuestion(i, j, k, l):\n",
    "    global json_data, json_dataPOS, json_dataOrg, json_dataPOSOrg, dictDoc, dictDocOrg\n",
    "    openclassword=[]\n",
    "    kindOfAnswer = []\n",
    "    questionPOS = json_dataPOS[i][0][j]\n",
    "    questionNER = json_data[i][0][j]        \n",
    "    answerPOS = json_dataPOS[i][l][k]\n",
    "    answerNER = json_data[i][l][k]\n",
    "    specialcommand=[]\n",
    "    #print questionNER, answerPOS\n",
    "    originalWithout = [x[0] for x in questionPOS]\n",
    "    originalWithoutA = [x[0] for x in answerPOS]\n",
    "    getIndexOfWH = [y for y,x in enumerate(questionPOS) if 'W' in x[1]]\n",
    "    #if wh\n",
    "    if len(getIndexOfWH) != 0:\n",
    "        getPOS = ''.join([x[1][0] for x in questionPOS])        \n",
    "        \n",
    "        #not at last word\n",
    "        if getIndexOfWH[0]+1!=len(questionPOS):            \n",
    "            searchWordAfterWh1 = re.search('W(.*?)V', getPOS, re.IGNORECASE)\n",
    "            if searchWordAfterWh1:\n",
    "                if len(searchWordAfterWh1.group(1))!=0:\n",
    "                    openclassword.append([searchWordAfterWh1.start()+len(searchWordAfterWh1.group(1))])                    \n",
    "                else:\n",
    "                    openclassword.append([])\n",
    "            else:\n",
    "                searchWordAfterWh1 = re.search('W(.*?)', getPOS, re.IGNORECASE)\n",
    "                if searchWordAfterWh1:\n",
    "                    openclassword.append([searchWordAfterWh1.start()+len(searchWordAfterWh1.group(0))-1])\n",
    "                else:\n",
    "                    openclassword.append([])\n",
    "            frontPart = range(0,searchWordAfterWh1.start()) if searchWordAfterWh1 else range(0,len(getPOS)/2)\n",
    "            backPart = range(searchWordAfterWh1.start()+len(searchWordAfterWh1.group(0)),len(getPOS)) if searchWordAfterWh1 else range(len(getPOS)/2,len(getPOS))                      \n",
    "            openclassword.append(frontPart+backPart)      \n",
    "            #print openclassword\n",
    "        else:\n",
    "            openclassword=[[],[y for y,x in enumerate(questionPOS)][:-1]]                        \n",
    "        #remove Stopwords        \n",
    "        openclassword[1] = [x for x in openclassword[1] if questionPOS[x][0] not in stop]\n",
    "        if len(openclassword[0])!=0:            \n",
    "            numberIndicator = ['year','length','percentage', 'many','much']            \n",
    "            for x in numberIndicator: \n",
    "                for y in originalWithout[getIndexOfWH[0]:openclassword[0][0]+2]:\n",
    "                    if x in y:\n",
    "                        kindOfAnswer = ['NUMBER'] if len(kindOfAnswer)==0 else kindOfAnswer\n",
    "                        specialcommand.append(x)\n",
    "            personIndicator = ['name']\n",
    "            for x in personIndicator:\n",
    "                for y in originalWithout[getIndexOfWH[0]:openclassword[0][0]+2]:\n",
    "                    if x in y:\n",
    "                        kindOfAnswer = ['PERSON','ORGANIZATION'] if len(kindOfAnswer)==0 else kindOfAnswer\n",
    "            placeIndicator = ['location','place','country','city','area']\n",
    "            for x in placeIndicator:\n",
    "                for y in originalWithout[getIndexOfWH[0]:openclassword[0][0]+2]:\n",
    "                    if x in y:\n",
    "                        kindOfAnswer = ['LOCATION'] if len(kindOfAnswer)==0 else kindOfAnswer\n",
    "                        specialcommand=['location']\n",
    "            if len(kindOfAnswer)==0:    \n",
    "                kindOfAnswer = ['O','U']\n",
    "        else:\n",
    "            numberIndicator = ['when']            \n",
    "            personIndicator = ['who','whom','whose','name']\n",
    "            placeIndicator = ['where','located']\n",
    "            if originalWithout[getIndexOfWH[0]] in numberIndicator:\n",
    "                kindOfAnswer = ['NUMBER']\n",
    "                specialcommand = ['year']\n",
    "            elif originalWithout[getIndexOfWH[0]] in personIndicator:\n",
    "                kindOfAnswer = ['PERSON','ORGANIZATION']\n",
    "            elif originalWithout[getIndexOfWH[0]] in placeIndicator:\n",
    "                kindOfAnswer = ['LOCATION']\n",
    "                specialcommand=['location']\n",
    "            else:\n",
    "                if len([y for y in openclassword[1] if questionPOS[y][0] in personIndicator])!=0:\n",
    "                    kindOfAnswer = ['PERSON','ORGANIZATION']\n",
    "                elif len([y for y in openclassword[1] if questionPOS[y][0] in placeIndicator])!=0:\n",
    "                    kindOfAnswer = ['LOCATION']\n",
    "                    specialcommand=['location']\n",
    "                else: \n",
    "                    kindOfAnswer = ['O','U']\n",
    "    else:\n",
    "        openclassword = [[],[x for x,y in enumerate(originalWithout) if y not in stop]]\n",
    "        kindOfAnswer = ['O','U']\n",
    "    #determine whether it requires number entity\n",
    "    newList1=[]\n",
    "    newList2=[]\n",
    "    for x in range(len(openclassword[0])):\n",
    "        if originalWithout[openclassword[0][x]] in originalWithoutA:            \n",
    "            newList1.extend([f for f,h in enumerate(originalWithoutA) if originalWithout[openclassword[0][x]] == h])        \n",
    "    for x in range(len(openclassword[1])):\n",
    "        if originalWithout[openclassword[1][x]] in originalWithoutA:\n",
    "            newList2.extend([f for f,h in enumerate(originalWithoutA) if originalWithout[openclassword[1][x]] == h])\n",
    "    openclassword[0]=newList1\n",
    "    openclassword[1]=newList2\n",
    "    return openclassword, kindOfAnswer,specialcommand   \n",
    "                    \n",
    "def tokenizeUnicode(aUnicode):\n",
    "    return word_tokenize(re.sub(',', '',re.sub('[^a-zA-Z0-9-_*., ]', ' ',aUnicode)))\n",
    "\n",
    "def removeUnicode(aUnicode):\n",
    "    return re.sub(',', '',re.sub('[^a-zA-Z0-9-_*., ]', ' ',aUnicode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readCSV(filename,l):\n",
    "    global json_data, json_dataPOS, json_dataOrg, json_dataPOSOrg, dictDoc, dictDocOrg\n",
    "    csv_file = filename\n",
    "    i=0\n",
    "    answerSecondFilter = []\n",
    "    dictDoc={}\n",
    "    dictDocOrg={}\n",
    "    question={}\n",
    "    with open(csv_file, 'rb') as csvfile:\n",
    "        readCSV = csv.DictReader(csvfile, delimiter=',')\n",
    "        for row in readCSV:\n",
    "            document_i = int(row['document_ID'])\n",
    "            question_i = int(row['question_ID'])\n",
    "            filteredlistOfNERSentence = []\n",
    "            question_type = []\n",
    "            predictionList = ast.literal_eval(row['prediction_ID'])\n",
    "            #try:\n",
    "            question_type = detectQuestion(document_i,question_i,predictionList[0] if len(predictionList)!=0 else 1,l) \n",
    "            \n",
    "            #except: print document_i,question_i,predictionList[0] if len(predictionList)!=0 else 1\n",
    "            question[document_i,question_i] = row['question']        \n",
    "            dictDoc[document_i,question_i]=predictionList[0] if len(predictionList)!=0 else 1,question_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def returnAnswer(i,j,l):\n",
    "    global json_data, json_dataPOS, json_dataOrg, json_dataPOSOrg, dictDoc, dictDocOrg\n",
    "    answerListPOS = json_dataPOS[i][l][dictDoc[i,j][0]]    \n",
    "    answerListNER = json_data[i][l][dictDoc[i,j][0]]    \n",
    "    question_type = dictDoc[i,j][1][1]\n",
    "    #print answerListPOS,question_type\n",
    "    question_typeLocationInAnswer = [x for x,y in enumerate(answerListNER) if ('CD' in answerListPOS[answerListNER.index(y)][1] or 'NN' in answerListPOS[answerListNER.index(y)][1]) and y[1] in question_type and y[0] not in stop and x not in dictDoc[i,j][1][0][0] and x not in dictDoc[i,j][1][0][1]]\n",
    "    #print question_typeLocationInAnswer\n",
    "    if len(question_typeLocationInAnswer) ==0:\n",
    "        question_typeLocationInAnswer = [x for x,y in enumerate(answerListNER) if ('CD' in answerListPOS[answerListNER.index(y)][1] or 'NN' in answerListPOS[answerListNER.index(y)][1]) and y[0] not in stop and x not in dictDoc[i,j][1][0][0] and x not in dictDoc[i,j][1][0][1]]\n",
    "    #print question_typeLocationInAnswer,dictDoc[i,j][1][0][1], dictDoc[i,j][1][0][0]\n",
    "    scoreList = 0\n",
    "    if len(dictDoc[i,j][1][0][0])!=0:\n",
    "        maxScore = sys.maxint        \n",
    "        for x in question_typeLocationInAnswer:\n",
    "            score = sum([math.fabs(z-x) for z in dictDoc[i,j][1][0][0]])\n",
    "            if maxScore>score:\n",
    "                maxScore=score\n",
    "                scoreList = x\n",
    "    else:\n",
    "        maxScore = sys.maxint\n",
    "        scoreList = 0\n",
    "        for x in question_typeLocationInAnswer:\n",
    "            score = sum([math.fabs(z-x) for z in dictDoc[i,j][1][0][1]])\n",
    "            if maxScore>score:\n",
    "                maxScore=score\n",
    "                scoreList = x\n",
    "    #print json_dataPOSOrg[i][2][dictDoc[i,j][0]][scoreList][0]\n",
    "    #print dictDoc[i,j][1][2]\n",
    "    return createNP((json_dataPOSOrg[i][l][dictDoc[i,j][0]][scoreList][0],scoreList),json_dataPOSOrg[i][l][dictDoc[i,j][0]],dictDoc[i,j][1][2],i,dictDoc[i,j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createNP(answerToReturn,answerPOS,specialcommand,q,j):\n",
    "    global json_data, json_dataPOS, json_dataOrg, json_dataPOSOrg, dictDoc, dictDocOrg\n",
    "    newAnswer = answerPOS[answerToReturn[1]][0]\n",
    "    if (newAnswer.isdigit() and 'year' not in specialcommand):\n",
    "        newAnswer = \"{:,}\".format(int(answerPOS[answerToReturn[1]][0]))\n",
    "    for i in range(answerToReturn[1],0,-1):\n",
    "        if answerToReturn[1] != 0:\n",
    "            if answerPOS[i][1] =='NNP':\n",
    "                if 'NNP' in answerPOS[i-1][1] or (('DT' in answerPOS[i-1][1] or 'IN' in answerPOS[i-1][1]) and answerPOS[i-1][0] !='at' and 'location' in specialcommand):\n",
    "                    newAnswer = answerPOS[i-1][0]+ \" \" +newAnswer\n",
    "                else:\n",
    "                    break\n",
    "            elif answerPOS[i][1] =='NN':\n",
    "                if 'JJ' in answerPOS[i-1][1] or 'DT' in answerPOS[i-1][1] or 'CD' in answerPOS[i-1][1] or answerPOS[i-1][1] =='NN':\n",
    "                    newAnswer = answerPOS[i-1][0]+ \" \" +newAnswer\n",
    "                else:\n",
    "                    break\n",
    "            elif answerPOS[i][1] =='JJ':\n",
    "                if answerPOS[i-1][1] =='JJ':\n",
    "                    newAnswer = answerPOS[i-1][0]+ \" \" +newAnswer\n",
    "                else:\n",
    "                    break\n",
    "            elif answerPOS[i][1] =='NNS':\n",
    "                if 'JJ' in answerPOS[i-1][1]:\n",
    "                    newAnswer = answerPOS[i-1][0]+ \" \" +newAnswer\n",
    "                else:\n",
    "                    break\n",
    "            elif 'DT' in answerPOS[i][1] and 'location' not in specialcommand:\n",
    "                if 'TO' in answerPOS[i-1][1]:\n",
    "                    newAnswer = answerPOS[i-1][0]+ \" \" +newAnswer\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                if answerPOS[i][1] !='CD' and answerPOS[i][1] !='RB':\n",
    "                    if 'NN' in answerPOS[i-1][1] or 'JJ' in answerPOS[i-1][1] or 'RB' in answerPOS[i-1][1]:\n",
    "                        newAnswer = answerPOS[i-1][0]+ \" \" +newAnswer\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "    for i in range(answerToReturn[1],len(answerPOS)-1):\n",
    "        if answerToReturn[1] != len(answerPOS)-1:\n",
    "            if answerPOS[i][1] =='NNP':                \n",
    "                if 'NNP' in answerPOS[i+1][1] or 'CC' in answerPOS[i+1][1] or 'IN' in answerPOS[i+1][1] or 'TO' in answerPOS[i+1][1] or ('NN' in answerPOS[i+1][1] and 'location' in specialcommand):                                        \n",
    "                    newAnswer = newAnswer+' '+answerPOS[i+1][0]\n",
    "                else:                    \n",
    "                    break\n",
    "            elif answerPOS[i][1] =='CC':\n",
    "                if 'NNP' in answerPOS[i+1][1] or 'NN' == answerPOS[i+1][1]:\n",
    "                    newAnswer = newAnswer+' '+answerPOS[i+1][0]\n",
    "                else:                    \n",
    "                    break\n",
    "            elif answerPOS[i][1] =='CD':\n",
    "                if 'CD' in answerPOS[i+1][1]:                 \n",
    "                    newAnswer = newAnswer+' '+answerPOS[i+1][0]\n",
    "                else:                    \n",
    "                    break\n",
    "            elif answerPOS[i][1] =='TO' or answerPOS[i][1] =='DT':\n",
    "                if 'NN' in answerPOS[i+1][1] or 'RB' in answerPOS[i+1][1]:\n",
    "                    newAnswer = newAnswer+' '+answerPOS[i+1][0]\n",
    "                else:\n",
    "                    break \n",
    "            elif answerPOS[i][1] =='IN' and 'location' not in specialcommand:\n",
    "                if answerPOS[i+1][1] =='DT' or answerPOS[i+1][1] =='NNP' or answerPOS[i+1][1] =='TO' or answerPOS[i+1][1] =='CD':\n",
    "                    newAnswer = newAnswer+' '+answerPOS[i+1][0]\n",
    "                else:\n",
    "                    break\n",
    "            elif answerPOS[i][1] =='JJ':\n",
    "                if 'NNS' in answerPOS[i+1][1] or 'NN' == answerPOS[i+1][1] or answerPOS[i+1][1] =='JJ':\n",
    "                    newAnswer = newAnswer+' '+answerPOS[i+1][0]\n",
    "                else:\n",
    "                    break\n",
    "            elif answerPOS[i][1] =='NN':\n",
    "                if 'NN' in answerPOS[i+1][1] or 'JJ' in answerPOS[i+1][1] or 'IN' in answerPOS[i+1][1] or 'CC' in answerPOS[i+1][1]:\n",
    "                    newAnswer = newAnswer+' '+answerPOS[i+1][0]\n",
    "                else:\n",
    "                    break\n",
    "            elif answerPOS[i][1] =='NNS':\n",
    "                if 'IN' in answerPOS[i+1][1] and 'ORG' in specialcommand:\n",
    "                    newAnswer = newAnswer+' '+answerPOS[i+1][0]\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    buffernewAnswer1 = newAnswer.split()\n",
    "    if buffernewAnswer1[-1]=='along' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-6]\n",
    "    if buffernewAnswer1[-1]=='and' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-4]\n",
    "    if buffernewAnswer1[-1]=='for' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-4]\n",
    "    if buffernewAnswer1[-1]=='but' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-4]\n",
    "    if buffernewAnswer1[-1]=='in' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-3]\n",
    "    if buffernewAnswer1[-1]=='as' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-3]\n",
    "    if buffernewAnswer1[-1]=='at' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-3]\n",
    "    if buffernewAnswer1[-1]=='on' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-3]\n",
    "    if buffernewAnswer1[-1]=='to' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-3]\n",
    "    if buffernewAnswer1[-1]=='while' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-6]\n",
    "    if buffernewAnswer1[-1]=='despite' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-8]\n",
    "    if buffernewAnswer1[-1]=='because' and len(buffernewAnswer1)>1:\n",
    "        newAnswer=newAnswer[:-8]\n",
    "    if buffernewAnswer1[-1].isdigit() and len(buffernewAnswer1[-1])==4 and 'year' in specialcommand:\n",
    "        newAnswer=buffernewAnswer1[-1]\n",
    "    if buffernewAnswer1[-1].isdigit() and 'location' in specialcommand:\n",
    "        newAnswer=buffernewAnswer1[-1]\n",
    "    if len(specialcommand)!=0 and 'percentage' in specialcommand[0]:\n",
    "        newAnswer+='%'\n",
    "    if 'location' in specialcommand:\n",
    "        bufferNewAnswer=[]        \n",
    "        for x in newAnswer.split():\n",
    "            for y in json_dataOrg[q]['sentences'][j].split():\n",
    "                if x in y:\n",
    "                    bufferNewAnswer.append(y)\n",
    "                    break\n",
    "        newAnswer=' '.join(bufferNewAnswer)\n",
    "        newAnswer = newAnswer[:-1] if (len(newAnswer)>1 and not (newAnswer[-1].isalnum() or newAnswer[-1]=='%')) else newAnswer\n",
    "    newAnswer = newAnswer.replace(',','-COMMA-')\n",
    "    return newAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeToFile(filename,l):\n",
    "    global json_data, json_dataPOS, json_dataOrg, json_dataPOSOrg, dictDoc, dictDocOrg\n",
    "    with open(filename, mode='wb',) as csv_file:\n",
    "        fieldnames = ['document_id','question_id','answer_predict',\"answer_actual\",'tag','sentence','predict','question_type','question'] if l==2 else ['id','answer']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames,delimiter=',')\n",
    "        writer.writeheader()\n",
    "        k = 0\n",
    "        totalDoc=len(json_data)\n",
    "        for i in range(0, totalDoc):\n",
    "            for j in range(0,len(json_data[i][0])):\n",
    "                k+=1            \n",
    "                dictToCSV={}\n",
    "                if l == 2:\n",
    "                    dictToCSV['document_id'] = i\n",
    "                    dictToCSV['question_id'] = j\n",
    "                    dictToCSV['answer_predict']= returnAnswer(i,j,l)                    \n",
    "                    dictToCSV['answer_actual'] = json_dataOrg[i]['qa'][j]['answer']\n",
    "                    dictToCSV['tag'] =dictDoc[i,j]\n",
    "                    dictToCSV['question_type'] = dictDoc[i,j][1][1] if len(dictDoc[i,j][1])>=2 else 'O'\n",
    "                    dictToCSV['question'] = json_dataOrg[i]['qa'][j]['question']\n",
    "                    dictToCSV['sentence'] = json_dataOrg[i]['qa'][j]['answer_sentence']\n",
    "                    dictToCSV['predict'] = dictDoc[i,j][0]\n",
    "                else:\n",
    "                    dictToCSV={}\n",
    "                    dictToCSV['id'] = k\n",
    "                    #try:\n",
    "                    dictToCSV['answer'] = returnAnswer(i,j,l)\n",
    "                    #except:\n",
    "                     #   print '\\nError',i,j\n",
    "                writer.writerow(dictToCSV)    \n",
    "                csv_file.flush()\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.write(str(k))\n",
    "            sys.stdout.flush()\n",
    "    csv_file.close()\n",
    "    print '\\nsuccess' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import success\n",
      "8974\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "importNERPOSQA(\"data/NERtest.json\",\"data/POStest.json\",\"data/QA_test.json\")\n",
    "readCSV(\"data/bm25_test.csv\",1)\n",
    "writeToFile(\"data/bm25_test_result.csv\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import success\n",
      "8463\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "importNERPOSQA(\"data/NERdev.json\",\"data/POSdev.json\",\"data/QA_dev.json\")\n",
    "readCSV(\"data/bm25_dev.csv\",2)\n",
    "writeToFile(\"data/bm25_dev_result.csv\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import success\n",
      "70159\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "importNERPOSQA(\"data/NERtrain.json\",\"data/POStrain.json\",\"data/QA_train.json\")\n",
    "readCSV(\"data/tfidf_train.csv\",2)\n",
    "writeToFile(\"data/tfidf_train_result.csv\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
