{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math,numpy,json,re,nltk\n",
    "import time,re,os.path,sys\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from collections import defaultdict\n",
    "from numpy import multiply\n",
    "from math import sqrt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os.path as path\n",
    "from collections import OrderedDict\n",
    "from nltk.stem.wordnet import WordNetLemmatizer as WNL\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from nltk import FreqDist, DictionaryProbDist\n",
    "from operator import add\n",
    "import csv, ast\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "import sklearn\n",
    "import string\n",
    "path_to_jar = 'data/stanford-parser.jar'\n",
    "path_to_models_jar = 'data/stanford-parser-3.7.0-models.jar'\n",
    "st=PorterStemmer()\n",
    "stop = set(stopwords.words('english'))\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "input_file = \"data/traindata.csv\"\n",
    "input_filedev = \"data/devdata.csv\"\n",
    "\n",
    "df = pd.read_csv(input_file, header = 0)\n",
    "numpy_array = df.as_matrix().astype('U')\n",
    "dfdev = pd.read_csv(input_filedev, header = 0)\n",
    "numpy_arraydev = dfdev.as_matrix().astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X = tfidf_transformer.fit_transform(count_vect.fit_transform(numpy_array[:,0]))\n",
    "Y = numpy_array[:,1]\n",
    "Xdev=tfidf_transformer.transform(count_vect.transform(numpy_arraydev[:,0]))\n",
    "Ydev=numpy_arraydev[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfR = RandomForestClassifier().fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clfT = tree.DecisionTreeClassifier().fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clfLR = LogisticRegression().fit(X, Y)\n",
    "clfNB = MultinomialNB().fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=tfidf_transformer.transform(count_vect.transform(np.array(['What is the name of the largest mountain in Guam?'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'TAG']\n",
      "[u'O']\n",
      "[u'TAG']\n",
      "[u'TAG']\n"
     ]
    }
   ],
   "source": [
    "print clfR.predict(a)\n",
    "print clfT.predict(a)\n",
    "print clfLR.predict(a)\n",
    "print clfNB.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.788372917405\n"
     ]
    }
   ],
   "source": [
    "predictionR = clfR.predict(Xdev)\n",
    "print 'accuracy:',accuracy_score(predictionR,Ydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.810823585017\n"
     ]
    }
   ],
   "source": [
    "predictionLR = clfLR.predict(Xdev)\n",
    "print 'accuracy:',accuracy_score(predictionLR,Ydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.751979203592\n"
     ]
    }
   ],
   "source": [
    "predictionNB = clfNB.predict(Xdev)\n",
    "print 'accuracy:',accuracy_score(predictionNB,Ydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.763204537398\n"
     ]
    }
   ],
   "source": [
    "predictionT = clfT.predict(Xdev)\n",
    "print 'accuracy:',accuracy_score(predictionT,Ydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def returnProcessVector(predictionR,predictionLR,predictionNB,predictionT):\n",
    "    returnVector=[]\n",
    "    for xindex,x in enumerate(predictionR):\n",
    "        NER = set(['TAG']) & set([x,predictionLR[xindex],predictionNB[xindex],predictionT[xindex]])\n",
    "        if len(NER) != 0:\n",
    "            if predictionLR[xindex] != 'O':\n",
    "                returnVector.append(predictionLR[xindex])\n",
    "                continue\n",
    "            if predictionR[xindex] != 'O':\n",
    "                returnVector.append(predictionR[xindex])\n",
    "                continue\n",
    "            if predictionT[xindex] != 'O':\n",
    "                returnVector.append(predictionT[xindex])\n",
    "                continue\n",
    "            if predictionNB[xindex] != 'O':\n",
    "                returnVector.append(predictionNB[xindex])\n",
    "                continue\n",
    "        else:\n",
    "            returnVector.append('O')\n",
    "    return np.array(returnVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictionA = returnProcessVector(predictionR,predictionLR,predictionNB,predictionT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.779747134586\n"
     ]
    }
   ],
   "source": [
    "print 'accuracy:',accuracy_score(predictionA,Ydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
