{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic Q&A System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math,numpy,json,re,nltk\n",
    "import time,re,os.path,sys\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from collections import defaultdict\n",
    "from numpy import multiply\n",
    "from math import sqrt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os.path as path\n",
    "from collections import OrderedDict\n",
    "from nltk.stem.wordnet import WordNetLemmatizer as WNL\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from nltk import FreqDist, DictionaryProbDist\n",
    "from operator import add\n",
    "import csv, ast\n",
    "from nltk.tag.stanford import StanfordPOSTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Successful \n",
      "There are totally 40 documents in this dataset\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "filename_ls = ['QA_dev.json']\n",
    "dataset = []\n",
    "train_path = path.abspath('data/QA_dev.json')\n",
    "\n",
    "dataset = []\n",
    "with open(train_path) as f:\n",
    "    for line in f:\n",
    "        dataset+=(json.loads(line))\n",
    "print \"Import Successful \"\n",
    "print \"There are totally\", len(dataset),'documents in this dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build modle and evaluate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english')) # wrap in a set() (see below)\n",
    "stemmer = nltk.stem.PorterStemmer() \n",
    "\n",
    "def my_tokenizer(doc):\n",
    "    terms = set()\n",
    "    for token in nltk.word_tokenize(doc):\n",
    "        if token not in stopwords: # 'in' and 'not in' operations are much faster over sets that lists\n",
    "            terms.add(stemmer.stem(token.lower()))\n",
    "    return list(terms)\n",
    "\n",
    "\n",
    "class MostRelevantSentenceModel(object):\n",
    "    def __init__(self, vectorizer, collection_matrix):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.collection_matrix = collection_matrix\n",
    "        feature_array = vectorizer.get_feature_names()\n",
    "        self.features = dict()\n",
    "        for index in range(len(feature_array)):\n",
    "            term = feature_array[index]\n",
    "            self.features[term] = index\n",
    "\n",
    "    def predict(self, queies):\n",
    "        predictions = [self.inverted_index_score(i) for i in  queies]\n",
    "        return predictions\n",
    "\n",
    "    def inverted_index_score(self, query_sent):\n",
    "        \"\"\"\n",
    "        now we implement inverted index to handle query\n",
    "        \n",
    "        :param query_sent: \n",
    "        :return: \n",
    "        \n",
    "        \"\"\"\n",
    "        query_words = my_tokenizer(query_sent)\n",
    "        score = defaultdict(float)\n",
    "\n",
    "        for w in query_words:\n",
    "            try:\n",
    "                col_i = self.features[w]\n",
    "                inverted_ix = self.collection_matrix[:, col_i]\n",
    "                for di in range(inverted_ix.shape[0]):\n",
    "                    score[di] += inverted_ix[di, 0]\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        index_score = sorted(score.items(), key=lambda (k, v): v, reverse=True)\n",
    "\n",
    "        if index_score:\n",
    "            top10_doc_index = [i[0] for i in index_score[:10]]\n",
    "            return top10_doc_index\n",
    "        else:\n",
    "            print 'error occured' ,query_sent\n",
    "            return -1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model_and_evaluate(model, query ,report=False):\n",
    "    evaluate_row = []\n",
    "    pred = model.predict(query)\n",
    "    quest_index = 0\n",
    "    for pred_index in pred:\n",
    "        drow = dict()\n",
    "        if report:\n",
    "            print pred_index\n",
    "        drow['question_ID'] = quest_index\n",
    "        drow['prediction_ID'] = pred_index\n",
    "        evaluate_row.append(drow)\n",
    "        quest_index += 1\n",
    "    return evaluate_row\n",
    "\n",
    "\n",
    "# #build model for each document collaction\n",
    "\n",
    "for document in dataset:\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=1, use_idf=True,norm='l1',stop_words=None, tokenizer=my_tokenizer)\n",
    "    document_collections_sents = document['sentences']\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(document_collections_sents)\n",
    "    document['model'] = MostRelevantSentenceModel(vectorizer=tfidf_vectorizer,collection_matrix=tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output with predtion and actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occured Who was the runner up?\n",
      "error occured Who was the runner up?\n",
      "error occured Where did it open?\n",
      "error occured What did the actof of milno do?\n",
      "error occured What is an Etsudiantinas? \n",
      "error occured What is crosspicking?\n",
      "Running time count: 198.904000044\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csv_file = open('data/evaluatin_dev_results.csv', mode='w',)\n",
    "fieldnames = ['document_ID', 'question_ID','question','prediction_ID','prediction_sentence']\n",
    "writer = csv.DictWriter(csv_file, fieldnames=fieldnames, )\n",
    "writer.writeheader()\n",
    "\n",
    "ddi = 0\n",
    "for document in dataset:\n",
    "    questions = [i['question'] for i in document['qa']]\n",
    "    model = document['model']\n",
    "    result_row = build_model_and_evaluate(model, questions)\n",
    "    doc_sents = document['sentences']\n",
    "    for r in result_row:\n",
    "        r['document_ID'] = ddi\n",
    "        r['question'] = questions[r['question_ID']].encode('utf-8')\n",
    "        r['prediction_sentence'] = doc_sents[r['prediction_ID'][0]].encode('utf-8')\n",
    "        writer.writerow(r)\n",
    "    ddi += 1\n",
    "print 'Running time count:', time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def json_load_byteified(file_handle):\n",
    "    return _byteify(json.load(file_handle, object_hook=_byteify),ignore_dicts=True)\n",
    "\n",
    "def _byteify(data, ignore_dicts = False):\n",
    "    # if this is a unicode string, return its string representation\n",
    "    if isinstance(data, unicode):\n",
    "        return data.encode('utf-8')\n",
    "    # if this is a list of values, return list of byteified values\n",
    "    if isinstance(data, list):\n",
    "        return [ _byteify(item, ignore_dicts=True) for item in data ]\n",
    "    # if this is a dictionary, return dictionary of byteified keys and values\n",
    "    # but only if we haven't already byteified it\n",
    "    if isinstance(data, dict) and not ignore_dicts:\n",
    "        return {\n",
    "            _byteify(key, ignore_dicts=True): _byteify(value, ignore_dicts=True)\n",
    "            for key, value in data.iteritems()\n",
    "        }\n",
    "    # if it's anything else, return it in its original form\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "java_path = \"C:\\\\Program Files\\\\Java\\\\jre1.8.0_131\\\\bin\" # replace this\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import success\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/QA_dev.json\") as json_file:\n",
    "    json_data = json_load_byteified(json_file)\n",
    "print 'import success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n",
      "Time spending: 297.029000044\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "st = StanfordNERTagger(cwd+'\\data\\english.all.3class.distsim.crf.ser.gz',cwd+'\\data\\stanford-ner.jar')\n",
    "\n",
    "if not os.path.isfile(\"data/NERdev.json\"):    \n",
    "    start = time.time()\n",
    "    progressT = len(json_data)    \n",
    "    listOfDocument=[]\n",
    "    i=0\n",
    "    for jd in json_data:\n",
    "        aList=[]\n",
    "        aList.append(st.tag_sents([word_tokenize(re.sub(',', '',re.sub('[^a-zA-Z0-9-_*., ]', ' ',x['question']))) for x in jd['qa']]))\n",
    "        #remove the below file if running on test set\n",
    "        aList.append(st.tag_sents([word_tokenize(re.sub(',', '',re.sub('[^a-zA-Z0-9-_*., ]', ' ',x['answer']))) for x in jd['qa']]))\n",
    "        aList.append(st.tag_sents([word_tokenize(re.sub(',', '',re.sub('[^a-zA-Z0-9-_*., ]', ' ',x))) for x in jd['sentences']]))\n",
    "        listOfDocument.append(aList)\n",
    "        i+=1\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(\"%d%%\" % (i*100/progressT))\n",
    "        sys.stdout.flush()    \n",
    "    for document in range(0,len(listOfDocument)):\n",
    "        #change [2] to [1] if test set\n",
    "        for sentence in range(0,len(listOfDocument[document][2])):\n",
    "            for word in range(0,len(listOfDocument[document][2][sentence])):   \n",
    "                listOfDocument[document][2][sentence][word]= (listOfDocument[document][2][sentence][word][0]\n",
    "                                                              ,listOfDocument[document][2][sentence][word][1] if not listOfDocument[document][2][sentence][word][0].isdigit() else u'NUMBER')\n",
    "    with open('data/NERdev.json', 'w') as outfile:\n",
    "        json.dump(listOfDocument, outfile)\n",
    "    end = time.time()\n",
    "    print '\\nTime spending:',end - start    \n",
    "else:    \n",
    "    print 'there is a file'\n",
    "with open(\"data/NERdev.json\") as json_file:\n",
    "        json_dataNER = json_load_byteified(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import success\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/QA_train.json\") as json_file:\n",
    "    json_data = json_load_byteified(json_file)\n",
    "print 'import success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35%"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "stPOS = StanfordPOSTagger(cwd+'\\\\data\\\\wsj-0-18-left3words-distsim.tagger',cwd+'\\data\\stanford-postagger.jar')\n",
    "\n",
    "if not os.path.isfile(\"data/POStrain.json\"):    \n",
    "    start = time.time()\n",
    "    progressT = len(json_data)    \n",
    "    listOfDocument=[]\n",
    "    i=0\n",
    "    for jd in json_data:\n",
    "        aList=[]        \n",
    "        aList.append(stPOS.tag_sents([word_tokenize(re.sub(',', '',re.sub('[^a-zA-Z0-9-_*., ]', ' ',x['question']))) for x in jd['qa']]))\n",
    "        #remove the below file if running on test set\n",
    "        aList.append(stPOS.tag_sents([word_tokenize(re.sub(',', '',re.sub('[^a-zA-Z0-9-_*., ]', ' ',x['answer']))) for x in jd['qa']]))\n",
    "        aList.append(stPOS.tag_sents([word_tokenize(re.sub(',', '',re.sub('[^a-zA-Z0-9-_*., ]', ' ',x))) for x in jd['sentences']]))\n",
    "        listOfDocument.append(aList)\n",
    "        i+=1\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(\"%d%%\" % (i*100/progressT))\n",
    "        sys.stdout.flush()    \n",
    "    with open('data/POStrain.json', 'w') as outfile:\n",
    "        json.dump(listOfDocument, outfile)\n",
    "    end = time.time()\n",
    "    print '\\nTime spending:',end - start    \n",
    "else:    \n",
    "    print 'there is a file'\n",
    "with open(\"data/POStrain.json\") as json_file:\n",
    "        json_dataNER = json_load_byteified(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Determine answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def detectQuestion(argument):\n",
    "    argument = tokenizeUnicode(argument.lower())\n",
    "    if 'what' in argument and len(set(argument) & set(['year','time','rankings',]))!=0:\n",
    "        return 'NUMBER'\n",
    "    elif 'who' in argument or 'whom' in argument or 'whose' in argument or \\\n",
    "            ('what' in argument and len(set(argument) & set(['name']))!=0):\n",
    "        return 'PERSON'\n",
    "    elif 'when' in argument:\n",
    "        return 'NUMBER'\n",
    "    elif 'where' in argument or 'what' in argument and len(set(argument) & set(['part']))!=0:\n",
    "        return 'LOCATION'\n",
    "    elif 'how' in argument and len(set(argument) & set(['many','much','long','far']))!=0:\n",
    "        return 'NUMBER'        \n",
    "    elif 'why' in argument:\n",
    "        return 'O'\n",
    "    elif 'which' in argument and len(set(argument) & set(['year',\"years\"]))!=0:\n",
    "        return 'NUMBER'\n",
    "    else:\n",
    "        return 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenizeUnicode(aUnicode):\n",
    "    return word_tokenize(re.sub(',', '',re.sub('[^a-zA-Z0-9-_*., ]', ' ',aUnicode)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import success\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/NERdev.json\") as json_file:\n",
    "    json_data = json_load_byteified(json_file)\n",
    "with open(\"data/POSdev.json\") as json_file:\n",
    "    json_dataPOS = json_load_byteified(json_file)\n",
    "with open(\"data/QA_dev.json\") as json_file:\n",
    "    json_dataOrg = json_load_byteified(json_file)\n",
    "    \n",
    "print 'import success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 8455\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'evaluatin_test_results.csv'\n",
    "i=0\n",
    "answerSecondFilter = []\n",
    "dictDoc={}\n",
    "question={}\n",
    "with open(csv_file) as csvfile:\n",
    "    readCSV = csv.DictReader(csvfile, delimiter=',')\n",
    "    for row in readCSV:        \n",
    "        document_i = int(row['document_ID'])\n",
    "        question_i = int(row['question_ID'])\n",
    "        filteredlistOfNERSentence = []\n",
    "        question_type = detectQuestion(row['question'])\n",
    "        question[document_i,question_i] = row['question']\n",
    "        for x in ast.literal_eval(row['prediction_ID']):\n",
    "            listOfNERSentence = json_data[document_i][1][x]                      \n",
    "            if question_type in [k[1] for k in listOfNERSentence]:\n",
    "                filteredlistOfNERSentence.append(x)\n",
    "                i+=1\n",
    "        dictDoc[document_i,question_i,question_type]=filteredlistOfNERSentence        \n",
    "print 'success',len(dictDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success with answer\n"
     ]
    }
   ],
   "source": [
    "dictDoc2 = {}\n",
    "dictDoc3 = {}\n",
    "for i,j,qtype in dictDoc:    \n",
    "    questionNNP = set([x[0] for x in json_dataPOS[i][0][j] if x[1] == 'NNP'])\n",
    "    maxCommon = 0\n",
    "    maxSentence = ''\n",
    "    for x in dictDoc[i,j,qtype]:\n",
    "        answerNNP = [y[0] for y in json_dataPOS[i][1][x] if y[1] == 'NNP']\n",
    "        compareIntersection = len(set(questionNNP)&set(answerNNP))\n",
    "        if compareIntersection > maxCommon:\n",
    "            maxCommon = compareIntersection\n",
    "            maxSentence = json_dataPOS[i][1][x], json_data[i][1][x]\n",
    "    if len(dictDoc[i,j,qtype]) != 0:\n",
    "        if len(maxSentence) == 0:\n",
    "            maxSentence = json_dataPOS[i][1][dictDoc[i,j,qtype][0]], json_data[i][1][dictDoc[i,j,qtype][0]]\n",
    "        if qtype != 'O':\n",
    "            dictDoc2[i,j]= ' '.join([k[0] for k in maxSentence[1] if k[1]==qtype])\n",
    "            dictDoc3[i,j] = maxSentence[1]\n",
    "        else:\n",
    "            dictDoc2[i,j]= ' '.join([k[0] for k in maxSentence[0] if k[1]=='NNP'])\n",
    "            dictDoc3[i,j] = maxSentence[0]\n",
    "print 'success with answer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nicholas Russia Napoleon III'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictDoc2[0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 8974\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csv_file = open('data/test_results.csv', mode='wb',)\n",
    "fieldnames = ['id', 'answer',]\n",
    "writer = csv.DictWriter(csv_file, fieldnames=fieldnames,delimiter=',')\n",
    "writer.writeheader()\n",
    "k = 0\n",
    "totalDoc=len(json_data)\n",
    "for i in range(0, totalDoc):\n",
    "    for j in range(0,len(json_data[i][0])):\n",
    "        k+=1\n",
    "        dictToCSV={}\n",
    "        dictToCSV['id'] = k\n",
    "        dictToCSV['answer'] = dictDoc2.get((i,j),'NOT SURE')\n",
    "        writer.writerow(dictToCSV)    \n",
    "print 'success',k    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 8455\n",
      "success with answer\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'data/evaluatin_dev_results.csv'\n",
    "i=0\n",
    "answerSecondFilter = []\n",
    "dictDoc={}\n",
    "question={}\n",
    "with open(csv_file) as csvfile:\n",
    "    readCSV = csv.DictReader(csvfile, delimiter=',')\n",
    "    for row in readCSV:        \n",
    "        document_i = int(row['document_ID'])\n",
    "        question_i = int(row['question_ID'])\n",
    "        filteredlistOfNERSentence = []\n",
    "        question_type = detectQuestion(row['question'])\n",
    "        question[document_i,question_i] = row['question']\n",
    "        for x in ast.literal_eval(row['prediction_ID']):\n",
    "            listOfNERSentence = json_data[document_i][2][x]                      \n",
    "            if question_type in [k[1] for k in listOfNERSentence]:\n",
    "                filteredlistOfNERSentence.append(x)\n",
    "                i+=1\n",
    "        dictDoc[document_i,question_i,question_type]=filteredlistOfNERSentence        \n",
    "print 'success',len(dictDoc)\n",
    "dictDoc2 = {}\n",
    "dictDoc3 = {}\n",
    "for i,j,qtype in dictDoc:    \n",
    "    questionNNP = set([x[0] for x in json_dataPOS[i][0][j] if x[1] == 'NNP'])\n",
    "    maxCommon = 0\n",
    "    maxSentence = ''\n",
    "    for x in dictDoc[i,j,qtype]:\n",
    "        answerNNP = [y[0] for y in json_dataPOS[i][2][x] if y[1] == 'NNP']\n",
    "        compareIntersection = len(set(questionNNP)&set(answerNNP))\n",
    "        if compareIntersection > maxCommon:\n",
    "            maxCommon = compareIntersection\n",
    "            maxSentence = json_dataPOS[i][2][x], json_data[i][2][x]\n",
    "    if len(dictDoc[i,j,qtype]) != 0:\n",
    "        if len(maxSentence) == 0:\n",
    "            maxSentence = json_dataPOS[i][2][dictDoc[i,j,qtype][0]], json_data[i][2][dictDoc[i,j,qtype][0]]\n",
    "        if qtype != 'O':\n",
    "            dictDoc2[i,j]= ' '.join([k[0] for k in maxSentence[1] if k[1]==qtype])\n",
    "            dictDoc3[i,j] = maxSentence[1]\n",
    "        else:\n",
    "            dictDoc2[i,j]= ' '.join([k[0] for k in maxSentence[0] if k[1]=='NNP'])\n",
    "            dictDoc3[i,j] = maxSentence[0]\n",
    "print 'success with answer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Where', 'O'],\n",
       " ['is', 'O'],\n",
       " ['Calder', 'O'],\n",
       " ['Park', 'O'],\n",
       " ['Thunderdome', 'O']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[39][0][97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csv_file = open('data/dev_results.csv', mode='wb',)\n",
    "fieldnames = ['document_i','question_i','question', 'answer','actual','sentence_answer','sentence_actual']\n",
    "writer = csv.DictWriter(csv_file, fieldnames=fieldnames,delimiter=',')\n",
    "writer.writeheader()\n",
    "k = 0\n",
    "totalDoc=len(json_data)\n",
    "for i in range(0, totalDoc):\n",
    "    for j in range(0,len(json_data[i][0])):\n",
    "        dictToCSV={}\n",
    "        dictToCSV['document_i'] = i\n",
    "        dictToCSV['question_i'] = j\n",
    "        dictToCSV['question'] = json_dataOrg[i]['qa'][j]['question']\n",
    "        dictToCSV['answer'] = dictDoc2.get((i,j),'NOT SURE')\n",
    "        dictToCSV['actual'] = str(json_dataPOS[i][1][j])+' '+str(json_data[i][1][j])\n",
    "        dictToCSV['sentence_answer'] = dictDoc3.get((i,j),'NO ANSWER')\n",
    "        dictToCSV['sentence_actual'] = json_dataOrg[i]['sentences'][json_dataOrg[i]['qa'][j]['answer_sentence']]\n",
    "        writer.writerow(dictToCSV)    \n",
    "print 'success',k  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
